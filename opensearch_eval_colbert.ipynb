{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценка качества поиска (BM25 + kNN + ColBERT) через сервис `/search`\n",
    "\n",
    "Этот ноутбук:\n",
    "- берёт тестовые запросы из `test_queries_bank_docs.json`;\n",
    "- для каждого запроса вызывает HTTP‑эндпоинт `POST http://127.0.0.1:8000/search` твоего сервиса;\n",
    "- сортирует документы по полю `_colbert_score`;\n",
    "- считает метрики `precision@k`, `recall@k` и `nDCG@k` на уровне чанка и файла.\n",
    "\n",
    "По умолчанию используется индекс `makar_ozon`, но можно подставить любой `index_name` (например, `makar_ozon_semantic`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://llm.api.cloud.yandex.net/foundationModels/v1/textEmbedding'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "YANDEX_API_KEY = os.getenv(\"YANDEX_API_KEY\")\n",
    "YANDEX_FOLDER_ID = os.getenv(\"YANDEX_FOLDER_ID\")\n",
    "\n",
    "if not YANDEX_API_KEY:\n",
    "    raise ValueError(\"YANDEX_API_KEY must be set in environment variables\")\n",
    "if not YANDEX_FOLDER_ID:\n",
    "    raise ValueError(\"YANDEX_FOLDER_ID must be set in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENSEARCH_HOST: localhost\n",
      "OPENSEARCH_PORT: 9200\n",
      "OPENSEARCH_INDEX: makar_ozon\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import subprocess\n",
    "from typing import List, Dict, Any\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENSEARCH_HOST = os.getenv(\"OPENSEARCH_HOST\")\n",
    "OPENSEARCH_PORT = os.getenv(\"OPENSEARCH_PORT\")\n",
    "OPENSEARCH_INDEX = os.getenv(\"OPENSEARCH_INDEX\", \"makar_ozon\")\n",
    "\n",
    "if not OPENSEARCH_HOST:\n",
    "    raise ValueError(\"OPENSEARCH_HOST must be set in environment variables\")\n",
    "if not OPENSEARCH_PORT:\n",
    "    raise ValueError(\"OPENSEARCH_PORT must be set in environment variables\")\n",
    "\n",
    "OPENSEARCH_PORT = int(OPENSEARCH_PORT)\n",
    "\n",
    "TOP_K = 20\n",
    "KS = (1, 3, 5, 10, 15, 20)\n",
    "QUERIES_PATH = \"test_queries_bank_docs.json\"\n",
    "SEARCH_URL = \"http://127.0.0.1:8000/search\"\n",
    "\n",
    "print(\"OPENSEARCH_HOST:\", OPENSEARCH_HOST)\n",
    "print(\"OPENSEARCH_PORT:\", OPENSEARCH_PORT)\n",
    "print(\"OPENSEARCH_INDEX:\", OPENSEARCH_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "YANDEX_API_KEY = os.getenv(\"YANDEX_API_KEY\")\n",
    "YANDEX_FOLDER_ID = os.getenv(\"YANDEX_FOLDER_ID\")\n",
    "\n",
    "if not YANDEX_API_KEY:\n",
    "    raise ValueError(\"YANDEX_API_KEY must be set in environment variables\")\n",
    "if not YANDEX_FOLDER_ID:\n",
    "    raise ValueError(\"YANDEX_FOLDER_ID must be set in environment variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENSEARCH_HOST: localhost\n",
      "OPENSEARCH_PORT: 9200\n",
      "OPENSEARCH_INDEX: makar_ozon\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENSEARCH_HOST = os.getenv(\"OPENSEARCH_HOST\")\n",
    "OPENSEARCH_PORT = os.getenv(\"OPENSEARCH_PORT\")\n",
    "OPENSEARCH_INDEX = os.getenv(\"OPENSEARCH_INDEX\", \"makar_ozon\")\n",
    "\n",
    "if not OPENSEARCH_HOST:\n",
    "    raise ValueError(\"OPENSEARCH_HOST must be set in environment variables\")\n",
    "if not OPENSEARCH_PORT:\n",
    "    raise ValueError(\"OPENSEARCH_PORT must be set in environment variables\")\n",
    "\n",
    "OPENSEARCH_PORT = int(OPENSEARCH_PORT)\n",
    "\n",
    "TOP_K = 20\n",
    "KS = (1, 3, 5, 10, 15, 20)\n",
    "QUERIES_PATH = \"test_queries_bank_docs.json\"\n",
    "SEARCH_URL = \"http://127.0.0.1:8000/search\"\n",
    "\n",
    "print(\"OPENSEARCH_HOST:\", OPENSEARCH_HOST)\n",
    "print(\"OPENSEARCH_PORT:\", OPENSEARCH_PORT)\n",
    "print(\"OPENSEARCH_INDEX:\", OPENSEARCH_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def eval_queries_colbert(\n",
    "    index_name: str = OPENSEARCH_INDEX,\n",
    "    top_k: int = TOP_K,\n",
    "    ks: List[int] = list(KS),\n",
    ") -> None:\n",
    "    \"\"\"Прогоняет все запросы из JSON через HTTP‑эндпоинт /search и считает метрики.\n",
    "\n",
    "    Считаются две группы метрик:\n",
    "    - по точному совпадению чанка (source + chunk_id),\n",
    "    - по совпадению только имени файла (source), независимо от chunk_id.\n",
    "\n",
    "    Результаты сортируются по `_colbert_score` (если он есть в ответе).\n",
    "    \"\"\"\n",
    "    with open(QUERIES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        data: List[Dict[str, Any]] = json.load(f)\n",
    "\n",
    "    hits_doc_at_k = {k: 0 for k in ks}\n",
    "    prec_doc_at_k_sum = {k: 0.0 for k in ks}\n",
    "    ndcg_doc_at_k_sum = {k: 0.0 for k in ks}\n",
    "\n",
    "    hits_file_at_k = {k: 0 for k in ks}\n",
    "    prec_file_at_k_sum = {k: 0.0 for k in ks}\n",
    "    ndcg_file_at_k_sum = {k: 0.0 for k in ks}\n",
    "\n",
    "    total = len(data)\n",
    "    print(f\"Loaded {total} queries from {QUERIES_PATH}\")\n",
    "\n",
    "    for ex in data:\n",
    "        q = ex[\"question\"]\n",
    "        target_source = ex[\"source\"]\n",
    "        target_chunk = ex[\"chunk_id\"]\n",
    "\n",
    "        payload = {\n",
    "            \"query\": q,\n",
    "            \"size\": top_k,\n",
    "            \"index_name\": index_name,\n",
    "            \"use_hyde\": False,\n",
    "            \"use_colbert\": True,\n",
    "        }\n",
    "\n",
    "        curl_cmd = [\n",
    "            \"curl\",\n",
    "            \"-sS\",\n",
    "            \"-X\",\n",
    "            \"POST\",\n",
    "            SEARCH_URL,\n",
    "            \"-H\",\n",
    "            \"accept: application/json\",\n",
    "            \"-H\",\n",
    "            \"Content-Type: application/json\",\n",
    "            \"-d\",\n",
    "            json.dumps(payload, ensure_ascii=False),\n",
    "        ]\n",
    "        res = subprocess.run(\n",
    "            curl_cmd,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "        if res.returncode != 0:\n",
    "            print(\"curl error:\", res.stderr[:200])\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            resp = json.loads(res.stdout)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON decode error:\", e, \"raw:\", res.stdout[:300])\n",
    "            continue\n",
    "\n",
    "        docs = resp.get(\"documents\") or []\n",
    "\n",
    "        docs = sorted(\n",
    "            docs,\n",
    "            key=lambda d: (\n",
    "                d.get(\"_colbert_score\") is not None,\n",
    "                d.get(\"_colbert_score\") or 0.0,\n",
    "            ),\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        hit_doc_rank = None\n",
    "        hit_file_rank = None\n",
    "        for i, d in enumerate(docs, 1):\n",
    "            src = d.get(\"source\")\n",
    "            cid = d.get(\"chunk_id\")\n",
    "            if hit_doc_rank is None and src == target_source and cid == target_chunk:\n",
    "                hit_doc_rank = i\n",
    "            if hit_file_rank is None and src == target_source:\n",
    "                hit_file_rank = i\n",
    "            if hit_doc_rank is not None and hit_file_rank is not None:\n",
    "                break\n",
    "\n",
    "        for k in ks:\n",
    "            if hit_doc_rank is not None and hit_doc_rank <= k:\n",
    "                hits_doc_at_k[k] += 1\n",
    "                prec_doc_at_k_sum[k] += 1.0 / k\n",
    "                dcg_doc = 1.0 / math.log2(1 + hit_doc_rank)\n",
    "                ndcg_doc_at_k_sum[k] += dcg_doc\n",
    "\n",
    "            if hit_file_rank is not None and hit_file_rank <= k:\n",
    "                hits_file_at_k[k] += 1\n",
    "                prec_file_at_k_sum[k] += 1.0 / k\n",
    "                dcg_file = 1.0 / math.log2(1 + hit_file_rank)\n",
    "                ndcg_file_at_k_sum[k] += dcg_file\n",
    "\n",
    "    print(\n",
    "        f\"Evaluated {total} queries with TOP_K={top_k}, index='{index_name}' \"\n",
    "        f\"(ColBERT enabled via /search)\",\n",
    "    )\n",
    "    for k in ks:\n",
    "        recall_doc = hits_doc_at_k[k] / total\n",
    "        precision_doc = prec_doc_at_k_sum[k] / total\n",
    "        ndcg_doc = ndcg_doc_at_k_sum[k] / total\n",
    "\n",
    "        recall_file = hits_file_at_k[k] / total\n",
    "        precision_file = prec_file_at_k_sum[k] / total\n",
    "        ndcg_file = ndcg_file_at_k_sum[k] / total\n",
    "\n",
    "        print(\n",
    "            f\"k={k}: DOC  hits={hits_doc_at_k[k]}/{total} | \"\n",
    "            f\"recall@{k}={recall_doc:.3f} | precision@{k}={precision_doc:.3f} | ndcg@{k}={ndcg_doc:.3f}\",\n",
    "        )\n",
    "        print(\n",
    "            f\"      FILE hits={hits_file_at_k[k]}/{total} | \"\n",
    "            f\"recall_file@{k}={recall_file:.3f} | precision_file@{k}={precision_file:.3f} | ndcg_file@{k}={ndcg_file:.3f}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 28 queries from test_queries_bank_docs.json\n",
      "Evaluated 28 queries with TOP_K=20, index='makar_ozon' (ColBERT enabled via /search)\n",
      "k=1: DOC  hits=3/28 | recall@1=0.107 | precision@1=0.107 | ndcg@1=0.107\n",
      "      FILE hits=18/28 | recall_file@1=0.643 | precision_file@1=0.643 | ndcg_file@1=0.643\n",
      "k=3: DOC  hits=5/28 | recall@3=0.179 | precision@3=0.060 | ndcg@3=0.152\n",
      "      FILE hits=22/28 | recall_file@3=0.786 | precision_file@3=0.262 | ndcg_file@3=0.728\n",
      "k=5: DOC  hits=11/28 | recall@5=0.393 | precision@5=0.079 | ndcg@5=0.240\n",
      "      FILE hits=22/28 | recall_file@5=0.786 | precision_file@5=0.157 | ndcg_file@5=0.728\n",
      "k=10: DOC  hits=17/28 | recall@10=0.607 | precision@10=0.061 | ndcg@10=0.308\n",
      "      FILE hits=22/28 | recall_file@10=0.786 | precision_file@10=0.079 | ndcg_file@10=0.728\n",
      "k=15: DOC  hits=18/28 | recall@15=0.643 | precision@15=0.043 | ndcg@15=0.317\n",
      "      FILE hits=22/28 | recall_file@15=0.786 | precision_file@15=0.052 | ndcg_file@15=0.728\n",
      "k=20: DOC  hits=22/28 | recall@20=0.786 | precision@20=0.039 | ndcg@20=0.350\n",
      "      FILE hits=22/28 | recall_file@20=0.786 | precision_file@20=0.039 | ndcg_file@20=0.728\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "await eval_queries_colbert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 167 chunks from corpus.json\n",
      "Will generate questions for 30 random chunks\n",
      "[77] generating question…\n",
      "[117] generating question…\n",
      "[46] generating question…\n",
      "[83] generating question…\n",
      "[113] generating question…\n",
      "[155] generating question…\n",
      "[14] generating question…\n",
      "[119] generating question…\n",
      "[91] generating question…\n",
      "[40] generating question…\n",
      "[121] generating question…\n",
      "[24] generating question…\n",
      "[139] generating question…\n",
      "[148] generating question…\n",
      "[108] generating question…\n",
      "[146] generating question…\n",
      "[79] generating question…\n",
      "[81] generating question…\n",
      "[29] generating question…\n",
      "[125] generating question…\n",
      "[80] generating question…\n",
      "[115] generating question…\n",
      "[131] generating question…\n",
      "[89] generating question…\n",
      "[3] generating question…\n",
      "[62] generating question…\n",
      "[5] generating question…\n",
      "[0] generating question…\n",
      "[39] generating question…\n",
      "[48] generating question…\n",
      "Generated 30 query–chunk pairs\n",
      "Saved to test_queries_corpus.json\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import requests\n",
    "from typing import List\n",
    "\n",
    "CORPUS_PATH = \"corpus.json\"\n",
    "OUT_PATH = \"test_queries_corpus.json\"\n",
    "\n",
    "N_QUESTIONS = 30\n",
    "\n",
    "YANDEX_API_KEY = os.getenv(\"YANDEX_API_KEY\")\n",
    "YANDEX_FOLDER_ID = os.getenv(\"YANDEX_FOLDER_ID\")\n",
    "YANDEX_LLM_MODEL = os.getenv(\"YANDEX_LLM_MODEL\", \"yandexgpt-lite\")\n",
    "YANDEX_COMPLETION_URL = os.getenv(\n",
    "    \"YANDEX_COMPLETION_URL\",\n",
    "    \"https://llm.api.cloud.yandex.net/foundationModels/v1/completion\",\n",
    ")\n",
    "\n",
    "if not (YANDEX_API_KEY and YANDEX_FOLDER_ID):\n",
    "    raise ValueError(\"Нужно выставить YANDEX_API_KEY и YANDEX_FOLDER_ID в окружении\")\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Api-Key {YANDEX_API_KEY}\",\n",
    "    \"x-folder-id\": YANDEX_FOLDER_ID,\n",
    "    \"Content-Type\": \"application/json\",\n",
    "}\n",
    "\n",
    "\n",
    "def generate_question_for_chunk(text: str) -> str:\n",
    "    \"\"\"Генерирует один естественный вопрос по смыслу данного чанка.\"\"\"\n",
    "    snippet = text.strip().replace(\"\\n\", \" \")\n",
    "    if len(snippet) > 1200:\n",
    "        snippet = snippet[:1200]\n",
    "\n",
    "    prompt = (\n",
    "        \"Ты помогаешь составлять тестовые пользовательские запросы по текстам.\\n\"\n",
    "        \"Ниже дан фрагмент текста (чанк). Сформулируй ОДИН естественный, \"\n",
    "        \"конкретный вопрос на русском языке, который пользователь мог бы задать, \"\n",
    "        \"чтобы найти именно этот фрагмент. Не пиши ничего, кроме самого вопроса.\\n\\n\"\n",
    "        f\"Текст чанка:\\n{snippet}\\n\\n\"\n",
    "        \"Вопрос:\"\n",
    "    )\n",
    "\n",
    "    body = {\n",
    "        \"modelUri\": f\"gpt://{YANDEX_FOLDER_ID}/{YANDEX_LLM_MODEL}/latest\",\n",
    "        \"completionOptions\": {\n",
    "            \"stream\": False,\n",
    "            \"temperature\": 0.4,\n",
    "            \"maxTokens\": 120,\n",
    "        },\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"text\": prompt},\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    resp = requests.post(\n",
    "        YANDEX_COMPLETION_URL,\n",
    "        headers=headers,\n",
    "        json=body,\n",
    "        timeout=60,\n",
    "    )\n",
    "    resp.raise_for_status()\n",
    "    data = resp.json()\n",
    "\n",
    "    try:\n",
    "        text_out = data[\"result\"][\"alternatives\"][0][\"message\"][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Bad completion response: {data}\") from e\n",
    "\n",
    "    return text_out\n",
    "\n",
    "\n",
    "with open(CORPUS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus: List[Dict[str, Any]] = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(corpus)} chunks from {CORPUS_PATH}\")\n",
    "\n",
    "num_available = len(corpus)\n",
    "num_to_sample = min(N_QUESTIONS, num_available)\n",
    "all_indices = list(range(num_available))\n",
    "random.shuffle(all_indices)\n",
    "sample_indices = all_indices[:num_to_sample]\n",
    "\n",
    "print(f\"Will generate questions for {num_to_sample} random chunks\")\n",
    "\n",
    "results: List[Dict[str, Any]] = []\n",
    "\n",
    "for i in sample_indices:\n",
    "    item = corpus[i]\n",
    "    text = (item.get(\"text\") or \"\").strip()\n",
    "    if not text:\n",
    "        continue\n",
    "\n",
    "    print(f\"[{i}] generating question…\")\n",
    "    try:\n",
    "        q = generate_question_for_chunk(text)\n",
    "    except Exception as e:\n",
    "        print(f\"  error on chunk {i}: {e}\")\n",
    "        continue\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "            \"id\": i,\n",
    "            \"question\": q,\n",
    "            \"chunk_text\": text,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(f\"Generated {len(results)} query–chunk pairs\")\n",
    "\n",
    "with open(OUT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved to {OUT_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def eval_queries_corpus_text(\n",
    "    index_name: str = OPENSEARCH_INDEX,\n",
    "    top_k: int = TOP_K,\n",
    "    ks: List[int] = list(KS),\n",
    "    queries_path: str = \"test_queries_corpus.json\",\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Оценка поиска по test_queries_corpus.json:\n",
    "    - JSON: [{ \"id\": ..., \"question\": ..., \"chunk_text\": ... }, ...]\n",
    "    - релевантность определяется по точному совпадению текста чанка (поле text в выдаче).\n",
    "    \"\"\"\n",
    "    with open(queries_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data: List[Dict[str, Any]] = json.load(f)\n",
    "\n",
    "    hits_doc_at_k = {k: 0 for k in ks}\n",
    "    prec_doc_at_k_sum = {k: 0.0 for k in ks}\n",
    "    ndcg_doc_at_k_sum = {k: 0.0 for k in ks}\n",
    "\n",
    "    total = len(data)\n",
    "    print(f\"Loaded {total} queries from {queries_path}\")\n",
    "\n",
    "    for ex in data:\n",
    "        q = ex[\"question\"]\n",
    "        target_text = (ex[\"chunk_text\"] or \"\").strip()\n",
    "\n",
    "        payload = {\n",
    "            \"query\": q,\n",
    "            \"size\": top_k,\n",
    "            \"index_name\": index_name,\n",
    "            \"use_hyde\": False,\n",
    "            \"use_colbert\": True,\n",
    "        }\n",
    "\n",
    "        curl_cmd = [\n",
    "            \"curl\",\n",
    "            \"-sS\",\n",
    "            \"-X\",\n",
    "            \"POST\",\n",
    "            SEARCH_URL,\n",
    "            \"-H\",\n",
    "            \"accept: application/json\",\n",
    "            \"-H\",\n",
    "            \"Content-Type: application/json\",\n",
    "            \"-d\",\n",
    "            json.dumps(payload, ensure_ascii=False),\n",
    "        ]\n",
    "        res = subprocess.run(\n",
    "            curl_cmd,\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "        )\n",
    "        if res.returncode != 0:\n",
    "            print(\"curl error:\", res.stderr[:200])\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            resp = json.loads(res.stdout)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"JSON decode error:\", e, \"raw:\", res.stdout[:300])\n",
    "            continue\n",
    "\n",
    "        docs = resp.get(\"documents\") or []\n",
    "\n",
    "        docs = sorted(\n",
    "            docs,\n",
    "            key=lambda d: (\n",
    "                d.get(\"_colbert_score\") is not None,\n",
    "                d.get(\"_colbert_score\") or 0.0,\n",
    "            ),\n",
    "            reverse=True,\n",
    "        )\n",
    "\n",
    "        hit_doc_rank = None\n",
    "        for i, d in enumerate(docs, 1):\n",
    "            doc_text = (d.get(\"text\") or \"\").strip()\n",
    "            if doc_text == target_text:\n",
    "                hit_doc_rank = i\n",
    "                break\n",
    "\n",
    "        for k in ks:\n",
    "            if hit_doc_rank is not None and hit_doc_rank <= k:\n",
    "                hits_doc_at_k[k] += 1\n",
    "                prec_doc_at_k_sum[k] += 1.0 / k\n",
    "                dcg_doc = 1.0 / math.log2(1 + hit_doc_rank)\n",
    "                ndcg_doc_at_k_sum[k] += dcg_doc\n",
    "\n",
    "    print(\n",
    "        f\"Evaluated {total} queries with TOP_K={top_k}, index='{index_name}' \"\n",
    "        f\"(ground truth по тексту чанка из {queries_path})\",\n",
    "    )\n",
    "    for k in ks:\n",
    "        recall_doc = hits_doc_at_k[k] / total\n",
    "        precision_doc = prec_doc_at_k_sum[k] / total\n",
    "        ndcg_doc = ndcg_doc_at_k_sum[k] / total\n",
    "\n",
    "        print(\n",
    "            f\"k={k}: DOC  hits={hits_doc_at_k[k]}/{total} | \"\n",
    "            f\"recall@{k}={recall_doc:.3f} | precision@{k}={precision_doc:.3f} | ndcg@{k}={ndcg_doc:.3f}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENSEARCH_HOST: localhost\n",
      "OPENSEARCH_PORT: 9200\n",
      "OPENSEARCH_INDEX: makar_ozon\n",
      "Loaded 35 queries from /Users/admin/СДЭК/test_queries_semantic.json\n",
      "Evaluated 35 queries with TOP_K=20, index='makar_ozon_semantic' (ColBERT enabled via /search, corpus-json ground truth by chunk_text)\n",
      "k=1: DOC  hits=28/35 | recall@1=0.800 | precision@1=0.800 | ndcg@1=0.800\n",
      "k=3: DOC  hits=31/35 | recall@3=0.886 | precision@3=0.295 | ndcg@3=0.850\n",
      "k=5: DOC  hits=33/35 | recall@5=0.943 | precision@5=0.189 | ndcg@5=0.872\n",
      "k=10: DOC  hits=35/35 | recall@10=1.000 | precision@10=0.100 | ndcg@10=0.892\n",
      "k=15: DOC  hits=35/35 | recall@15=1.000 | precision@15=0.067 | ndcg@15=0.892\n",
      "k=20: DOC  hits=35/35 | recall@20=1.000 | precision@20=0.050 | ndcg@20=0.892\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "TOP_K = 20\n",
    "KS = (1, 3, 5)\n",
    "QUERIES_PATH = \"test_queries_bank_docs.json\"\n",
    "SEARCH_URL = \"http://127.0.0.1:8000/search\"\n",
    "\n",
    "print(\"OPENSEARCH_HOST:\", OPENSEARCH_HOST)\n",
    "print(\"OPENSEARCH_PORT:\", OPENSEARCH_PORT)\n",
    "print(\"OPENSEARCH_INDEX:\", OPENSEARCH_INDEX)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "await eval_queries_corpus_text(\n",
    "    index_name=\"makar_ozon_semantic\",\n",
    "    queries_path=\"test_queries_semantic.json\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
